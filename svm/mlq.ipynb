{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 支持向量机 SVM\n",
    "\n",
    "输入空间 $\\to$ 特征空间\n",
    "\n",
    "求解能够正确划分训练数据集并且**几何间隔最大**的分离超平面。\n",
    "\n",
    "支持向量机，面向**数据**的一个分类算法，确定**分类超平面**，从而将不同的数据分隔开。\n",
    "\n",
    "- 线性可分支持向量机\n",
    "  当训练数据**线性可分**时，通过**硬间隔最大化**，学习一个线性的分类器，即线性可分支持向量机，又称为硬间隔支持向量机\n",
    "- 线性支持向量机\n",
    "  当训练数据**近似线性可分**时，通过**软间隔最大化**，也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机\n",
    "- 非线性支持向量机\n",
    "  当训练数据**线性不可分**时，通过使用**核技巧**及**软间隔最大化**，学习非线性支持向量机。\n",
    "\n",
    "支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。\n",
    "\n",
    "对于任意线性可分的两组点,它们在SVM分类的超平面上的投影\n",
    "都是线性不可分的。\n",
    "\n",
    "**最佳超平面**: 以最大间隔把两类样本分开的超平面\n",
    "\n",
    "#### 原问题 \n",
    "- 任意超平面：\n",
    "$$\n",
    "w^T x + b = 0\n",
    "$$\n",
    "\n",
    "- 距离公式：\n",
    "$$\n",
    "d = \\frac{\\vert w^T x + b\\rvert}{\\lVert w \\rVert}\n",
    "$$\n",
    "其中，$\\lVert w \\rVert=\\sqrt{w_1^2 + \\cdots + w_n^2}$\n",
    "\n",
    "对于标记 $y=1$ 和 $y=-1$ 的数据点\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\frac{\\vert w^T x + b\\rvert}{\\lVert w \\rVert} \\geq d & y = 1\\\\[5pt]\n",
    "\\frac{\\vert w^T x + b\\rvert}{\\lVert w \\rVert} \\leq -d & y = -1\n",
    "\\end{cases}\n",
    "$$\n",
    "移项\n",
    "$$\n",
    "\\begin{cases}\n",
    "w^T x + b \\geq d\\lVert w \\rVert & y = 1\\\\[5pt]\n",
    "w^T x + b \\leq -d\\lVert w \\rVert & y = -1\n",
    "\\end{cases}\n",
    "$$\n",
    "其中，$\\lVert w \\rVert$ 是系数，所以可以调整 $w$ 使得 $d\\lVert w \\rVert \\equiv 1$。合并一下\n",
    "$$\n",
    "\\vert w^T x + b \\vert = y(w^T x + b) \\geq 1\n",
    "$$\n",
    "于是\n",
    "$$\n",
    "d = \\frac{\\vert w^T x + b\\rvert}{\\lVert w \\rVert} = \\frac{y(w^T x + b)}{\\lVert w \\rVert}\n",
    "$$\n",
    "因此，目标函数\n",
    "$$\n",
    "\\max~d = \\max~2 \\frac{1}{\\lVert w \\rVert}\n",
    "$$\n",
    "再转换一下\n",
    "$$\n",
    "\\max~d^2 = \\min~\\frac{1}{d^2} = \\min~ \\frac{1}{2}\\lVert w \\rVert^2\n",
    "$$\n",
    "最终，**最优化问题**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{w, b}~ \\quad &\\frac{1}{2}\\lVert w \\rVert^2 \\\\\n",
    "s.t.~ \\quad &y_i(w^Tx_i + b) -1 \\geq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "得到**分类决策函数**\n",
    "$$\n",
    "f(x) = \\text{sign}~({w^*}^Tx + b^{*})\n",
    "$$\n",
    "\n",
    "#### 存在性及唯一性\n",
    "\n",
    "#### 对偶问题\n",
    "> 优点：\n",
    "- 对偶问题更容易求解\n",
    "- 引入核函数，从而推广到非线性分类问题\n",
    "$$\n",
    " L(w,b,\\alpha) = \\frac{1}{2}\\lVert w \\rVert^2 -\n",
    " \\sum_{i=1}^n\\alpha_iy_i(w^Tx_i + b) + \\sum_{i=1}^n \\alpha_i\n",
    "$$\n",
    "原问题等价于\n",
    "$$\n",
    "\\max_\\alpha~\\min_{w,b}~L(w,b,\\alpha)\n",
    "$$\n",
    "1. 求 $\\min_{w,b}~L(w,b,\\alpha)$\n",
    "   $$\n",
    "   \\min_{w,b}~L(w,b,\\alpha) = -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i\\cdot y_i) + \\sum_{i=1}^N \\alpha_i\n",
    "   $$\n",
    "2. 求 $\\min_{w,b}~L(w,b,\\alpha)$ 对 $\\alpha$ 的极大  \n",
    "   等价于 $\\min~(-\\min_{w,b}~L(w,b,\\alpha))$ 即\n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   \\min~\\quad&\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(x_i\\cdot y_i) - \\sum_{i=1}^N \\alpha_i \\\\\n",
    "   s.t.~\\quad& \\sum_{i=1}^n\\alpha_iy_i=0\\\\\n",
    "   &\\alpha_i \\geq 0, \\quad i = 1, 2, \\dots, n\n",
    "   \\end{aligned}\n",
    "   $$\n",
    "3. 解得 $\\alpha^{*}$, 则\n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   w^{*} &= \\sum_{i=1}^n \\alpha_i^{*}y_ix_i\\\\ \n",
    "   b^{*} &= y_j - \\sum_{i=1}^n \\alpha_i^{*}y_i(x_i\\cdot x_j)\n",
    "   \\end{aligned}\n",
    "   $$\n",
    "4. 最终，分类决策函数\n",
    "   $$\n",
    "   f(x) = \\text{sign}\\left( \\sum_{i=1}^n \\alpha_i^{*}y_i(x\\cdot x_i) + b^{*} \\right)\n",
    "   $$\n",
    "### 算法只与少数支持向量有关\n",
    "KKT 互补条件\n",
    "$$\n",
    "\\alpha_i^{*}\\left[y_i(w^{*}\\cdot x_i + b^*)-1\\right] = 0, \\quad i = 1, 2, \\cdots, n\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}